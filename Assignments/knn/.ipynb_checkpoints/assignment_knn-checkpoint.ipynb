{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ef20f0-722f-4240-8a79-437d4a3b8832",
   "metadata": {},
   "source": [
    "## Assignment 3: $k$ Nearest Neighbor\n",
    "\n",
    "**Do two questions.**\n",
    "\n",
    "`! git clone https://github.com/DS3001/knn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c9e0b8-17f5-4ff9-9c76-2034bffe8d5c",
   "metadata": {},
   "source": [
    "**Q1.** This question is a case study for $k$ nearest neighbor The target variable `y` is `price` and the features are `year` and `mileage`.\n",
    "\n",
    "1. Load the `./data/USA_cars_datasets.csv`. Keep the following variables and drop the rest: `price`, `year`, `mileage`. Are there any `NA`'s to handle? Look at the head and dimensions of the data.\n",
    "2. Maxmin normalize `year` and `mileage`.\n",
    "3. Split the sample into ~80% for training and ~20% for evaluation.\n",
    "4. Use the $k$NN algorithm and the training data to predict `price` using `year` and `mileage` for the test set for $k=3,10,25,50,100,300$. For each value of $k$, compute the mean squared error and print a scatterplot showing the test value plotted against the predicted value. What patterns do you notice as you increase $k$?\n",
    "5. Determine the optimal $k$ for these data.\n",
    "6. Describe what happened in the plots of predicted versus actual prices as $k$ varied, taking your answer into part 6 into account. (Hint: Use the words \"underfitting\" and \"overfitting\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c487a50",
   "metadata": {},
   "source": [
    "**Q1.** This question is a case study for $k$ nearest neighbor The target variable `y` is `price` and the features are `year` and `mileage`.\n",
    "\n",
    "1. Load the `./data/USA_cars_datasets.csv`. Keep the following variables and drop the rest: `price`, `year`, `mileage`. Are there any `NA`'s to handle? Look at the head and dimensions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a479ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6300  2899  5350 25000 27700  5700  7300 13350 14600  5250 10400 12920\n",
      " 31900  5430 20700 12710  5200 16500  5210 38100 12520 15000  6180 20800\n",
      " 11900 21500 12000  4190 13000 18500 29800  5330 16600 19200  7320  7000\n",
      " 30500  6330 55000 16200 19000  5580 54000 16000 27000  7760 19600 20000\n",
      " 18100 23000 13490 17800  6650 29100 21100 18600  4340 19300 12780 15800\n",
      " 29400  4430 19400 15900 26400  4140 18300 17900  4640 24000 13200 18000\n",
      " 14900 11500  9110  7350 24500  9300 39800 53500 15110 34000 26502  5990\n",
      " 13600 23605 10780 13800 25201  7070  8700 18003  8530 23100 17000 34002\n",
      "  6980 20802  9200 26500 24802 28500 47500 23500 23505 10940 32100 53000\n",
      "  6830 26414  4160 19405  5690 25900 24005  5090 19500 32012  6800  4260\n",
      "     0 31802  7210 28402 33300  6700  6440 19900 37000  4040 22300 31200\n",
      "  4290 22800 19002 39000  6060 28800 40000  6140 21000 20105  6760 25800\n",
      "  5470 24502  7900 27305 15290 25502  3800  1400 18402   175 24503 15840\n",
      " 20500 21003  4200 17400 32001 15700 31009  3740  5000 31002  3160  8600\n",
      "  6000 12990    25  4410 22500  7420 13500 15500  3540 45500  4130 16300\n",
      "  4530 15600  4100 18200 10200  4080  1700  6200  3650 10500 43500  4610\n",
      "  3450 38500  6810  2900  4450  5800  4240 13700  8000 14200  7040  4700\n",
      " 30851  4880 14500  7600 13270 12800 33000  9280   900  7560 17100  8020\n",
      " 10300 22600 10480 22700  7410  7570 67000 18900 12560 11760 31700  7340\n",
      "  8200  3000  6530 12700   725  7400  9800  4400 10330  1800    50   720\n",
      "  2500  9190 10900 22809  5520  2320 23702  4050 14810  2960 24800  6270\n",
      "  1880 10050   225 26900  1420 27003   350  5600  6680 10120  3920  5630\n",
      "  2800  8850 18712  2220  6930  3440 50412   950  9270 11380  2725  3790\n",
      " 40514  1000  2925  3830 43402  1025 17200 54680  6940 13080 10630 43009\n",
      "  4600  4950  3760  3900  6240  4150 61200  6490 51502   250  8160  7770\n",
      "   200  1825  9210 58500   125  3960  5998  3700 15050 36300 55600  2630\n",
      "   450 20400  4320 33001 10000  5790 14750  4010  3550  3040 36400  4480\n",
      " 31003    75  4690 46900 10740 27102   500  5100 15010 23200  3390  3140\n",
      " 10440 23911 21400  5380 11000 30300  2300  4310 26012 48500  3330 11200\n",
      "  4730 24900  8350   475  3210  8430 25503 26000  8610 28000 84900 10840\n",
      "   100 11050  3570 25001 11100  4650  3820 29502  6160 10910  3810  3020\n",
      "  2000  3870 24811  5420  4750  1200  6470 32500  6900 11030  3460  3250\n",
      " 27705  7200 28714 27502 29314 27002 28214 29900 27202 14700  4500 25511\n",
      "  7700 27402  1500 26602 14000 29809 36900 26902 10950 16900 25600 29700\n",
      " 27702 25811 37500 26211 24205 27111 27411 27302 26311 33500 27511 27200\n",
      " 26511 24002 18511 29000 23402 13300 19700 23211 18111 17700 21700 35500\n",
      " 29500 25300 35300 62000 46000  9000 47400 24400 33100 22000 35000 11600\n",
      " 28100 63200 36800 38800 31100 22400 37100 32800 12300  9400 23800 31600\n",
      " 46800 21800 31500 34500 10700 13400 14100 38600  9100  8900  3300 17300\n",
      " 34800 32200 33200 24300 27500 10800 11400 42700 21200  9600 35100 26300\n",
      " 17600 19100 15200 16100 14800 16700 15300  6500 28300 27300  3500  8300\n",
      " 30000 21600 22100 14300 43400 12500 13900 17500 18700 27900  7500 20200\n",
      " 29300 31000 32400 23300  6100 52000 36000 12995 17750 10295 16995 23995\n",
      " 15810 20227 20999 22499 23495 25250 15322 21232  8500 28700  7100 30700\n",
      " 15400 25200 13100 28400 20300  1300  1750 16800 11800 27100  2200 18800\n",
      "  8400  4900 21900 13750 16400 15100 34100 33800 29600 27800 18400 32000\n",
      " 26800   800  1900  3600  2700  9700 48000 54500  5500 25500 25700 28200\n",
      " 42500 36500 20900 20100 26700 23900 17347 25888 21289 17999 30977 13799\n",
      "  9900 65500 36200  3200  8750 11975 23600 30900 40400 38000 23700 54900\n",
      " 24700 38200 23400 50500 49000 25400 35200 56700 40200 65200 63000 44000\n",
      " 70000 56200 57700 74000 60200 60000 41500 28600 46500 39500 46700 42800\n",
      " 30200 25100 56500 34300 37200 31800 46300 45000 49500  4000 47000 50000\n",
      " 47300  7805 44500 35700 43600 22900  7800  9500 12100 24100 12400 39700\n",
      " 38700 37700 22200 39950 37600 18288 36600 18299 30995   650 11300 32700\n",
      "  1350 11700  1150 20600 48400 46200 27600  2100 33700 33400 30600 14400\n",
      " 40600 43900  6400 41100 40900 39200 24200 12600  5300 24600 41200 49900\n",
      " 34400 10100 42300 51000 45600 19990 30999 41000 27999 42000 29795 13995\n",
      " 35400 24549 24970  2580 59975 28990 46999 34700 28900 30800 13388  1725\n",
      " 33995 24190 19888 24857 26100 20995 19498 19995 26985 34995 19440 20950\n",
      "  2825 32999  6600 50200 35999 18799 33999 25998 31831 25995 27990 23985\n",
      " 27995 29988 21687 29590 28999 13942  1850 15495 17589 31790 14495 23999\n",
      " 16488 12784  9705 25999 34977 15995 13487 18707 16080 15268 18497 17150\n",
      " 14295 16190 17899 16888  8305 21822 14488 21995 16593 14247 16999 20159\n",
      " 59900   825 26200 26550 56000 45800 11450 10850 10450 12200  5900 19800\n",
      "  8800   750  1280   600  6998  7998 10999  8495 19925 12750 11621 11590\n",
      " 11390 12900 10600  2425   925   375  4800  5475  1950 30100]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cars = pd.read_csv('USA_cars_datasets.csv')\n",
    "cars = cars.loc[:, ['price', 'year', 'mileage']]\n",
    "print(cars['price'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1000ebbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2008 2011 2018 2014 2010 2017 2009 2013 2015 2020 2016 1973 2003 2019\n",
      " 2002 2000 2001 2005 2012 2006 2007 1998 2004 1994 1997 1996 1999 1984\n",
      " 1995 1993]\n"
     ]
    }
   ],
   "source": [
    "print(cars['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f622383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274117 190552  39590 ...  34553  32557  31371]\n"
     ]
    }
   ],
   "source": [
    "print(cars['mileage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d33186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no NaN values it seems, just a weird '...' value which I'm unsure of whether it should be cleaned\n"
     ]
    }
   ],
   "source": [
    "print(\"There are no NaN values it seems, just a weird '...' value which I'm unsure of whether it should be cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d226844",
   "metadata": {},
   "source": [
    "2. Maxmin normalize `year` and `mileage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ab1bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESOURCES\n",
    "# https://towardsdatascience.com/data-normalization-with-pandas-and-scikit-learn-7c1cc6ed6475#:~:text=The%20min%2Dmax%20approach%20(often,max()%20methods.\n",
    "\n",
    "def min_max_scaling(df, columns):\n",
    "    # copy the dataframe\n",
    "    df_norm = df.copy()\n",
    "    # apply min-max scaling\n",
    "    for column in columns:\n",
    "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
    "        \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cc131a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price      year   mileage\n",
      "0   6300  0.744681  0.269287\n",
      "1   2899  0.808511  0.187194\n",
      "2   5350  0.957447  0.038892\n",
      "3  25000  0.872340  0.063016\n",
      "4  27700  0.957447  0.006537\n"
     ]
    }
   ],
   "source": [
    "df_cars_normalized = min_max_scaling(cars, ['year', 'mileage'])\n",
    "df['price'] = df['price'].astype(float)\n",
    "df['year'] = df['year'].astype(float)\n",
    "df['mileage'] = df['mileage'].astype(float)\n",
    "print(df_cars_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a7aaa0",
   "metadata": {},
   "source": [
    "3. Split the sample into ~80% for training and ~20% for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffee5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = df['price']\n",
    "X = df.drop('price',axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2,random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08f014",
   "metadata": {},
   "source": [
    "4. Use the $k$NN algorithm and the training data to predict `price` using `year` and `mileage` for the test set for $k=3,10,25,50,100,300$. For each value of $k$, compute the mean squared error and print a scatterplot showing the test value plotted against the predicted value. What patterns do you notice as you increase $k$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b376232",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'nissan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m25\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m300\u001b[39m]:\n\u001b[0;32m---> 10\u001b[0m     model \u001b[38;5;241m=\u001b[39m KNeighborsRegressor(n_neighbors\u001b[38;5;241m=\u001b[39mk)\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m     11\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     12\u001b[0m     SSE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( (y_test\u001b[38;5;241m-\u001b[39my_hat)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_regression.py:218\u001b[0m, in \u001b[0;36mKNeighborsRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# KNeighborsRegressor.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors regressor from the training dataset.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors regressor.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py:456\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 456\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    457\u001b[0m             X, y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m         )\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:2084\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2083\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 2084\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   2085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2086\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   2087\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   2088\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[1;32m   2089\u001b[0m     ):\n\u001b[1;32m   2090\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[1;32m   2091\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[1;32m   2092\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   2093\u001b[0m         ):\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'nissan'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "x_axis = 0\n",
    "y_axis = 0\n",
    "count = 0\n",
    "\n",
    "for k in [3,10,25,50,100,300]:\n",
    "    model = KNeighborsRegressor(n_neighbors=k).fit(X_train,y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    SSE = np.sum( (y_test-y_hat)**2 )\n",
    "    #\n",
    "    \n",
    "    count = count + 1\n",
    "    figure, axis = plt.subplots(2, 3) \n",
    "    if(count == 4):\n",
    "        x_axis = x_axis + 1\n",
    "        y_axix = 0\n",
    "\n",
    "    axis[x_axis, y_axis].scatter(y_test,y_hat)\n",
    "    axis[x_axis, y_axis].set_title(f\"k: {k}\") \n",
    "    y_axis = y_axis + 1\n",
    "    \n",
    "    axes.set_ylim(-1000, 62000)\n",
    "    axes.set_xlim(-1000, 62000)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da59d25",
   "metadata": {},
   "source": [
    "5. Determine the optimal $k$ for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc693bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'nissan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m SSE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(k_bar) \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_bar):\n\u001b[0;32m----> 6\u001b[0m     fitted_model \u001b[38;5;241m=\u001b[39m KNeighborsRegressor(n_neighbors\u001b[38;5;241m=\u001b[39mk\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X_train,y_train) \n\u001b[1;32m      7\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m fitted_model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;66;03m# Predict values for test set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     SSE[k] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum( (y_test\u001b[38;5;241m-\u001b[39my_hat)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m ) \u001b[38;5;66;03m# Save the computed SSE\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_regression.py:218\u001b[0m, in \u001b[0;36mKNeighborsRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# KNeighborsRegressor.metric is not validated yet\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the k-nearest neighbors regressor from the training dataset.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m        The fitted k-nearest neighbors regressor.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py:456\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[0;32m--> 456\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    457\u001b[0m             X, y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    458\u001b[0m         )\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;66;03m# Classification targets require a specific format\u001b[39;00m\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:2084\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m   2083\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 2084\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   2085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2086\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   2087\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   2088\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[1;32m   2089\u001b[0m     ):\n\u001b[1;32m   2090\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[1;32m   2091\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[1;32m   2092\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   2093\u001b[0m         ):\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'nissan'"
     ]
    }
   ],
   "source": [
    "k_bar = 200\n",
    "k_grid = np.arange(1,k_bar) # The range of k's to consider\n",
    "SSE = np.zeros(k_bar) \n",
    "\n",
    "for k in range(k_bar):\n",
    "    fitted_model = KNeighborsRegressor(n_neighbors=k+1).fit(X_train,y_train) \n",
    "    y_hat = fitted_model.predict(X_test) # Predict values for test set\n",
    "    SSE[k] = np.sum( (y_test-y_hat)**2 ) # Save the computed SSE\n",
    " \n",
    "SSE_min = np.min(SSE) # Lowest recorded SSE\n",
    "min_index = np.where(SSE==SSE_min) # Find the indices of y that equal the minimum\n",
    "k_star = k_grid[min_index] # Find the optimal value of k\n",
    "\n",
    "plt.plot(np.arange(0,k_bar),SSE) # Plot SSE by k\n",
    "plt.xlabel(\"k\")\n",
    "plt.title(f\"optimal k:{k_star}\")\n",
    "plt.ylabel('SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c511d5d",
   "metadata": {},
   "source": [
    "6. Describe what happened in the plots of predicted versus actual prices as $k$ varied, taking your answer into part 6 into account. (Hint: Use the words \"underfitting\" and \"overfitting\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b39c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In the case of a higher k, the model is likely overfitting the data since I found that the optimal value for k is 77 which makes sense since the data is much more horizontal and clustered than for other k values. On the other hand, for k=3, there is certainly underfitting going becuase the variance is high and there isn't enough clustering of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b57f7-bf4f-4494-b54c-49c4f3ae3ab9",
   "metadata": {},
   "source": [
    "**Q2.** This question is a case study for $k$ nearest neighbor. The data for the question include:\n",
    "\n",
    "- age: age of the patient (years)\n",
    "- anaemia: decrease of red blood cells or hemoglobin (boolean)\n",
    "- high blood pressure: if the patient has hypertension (boolean)\n",
    "- creatinine phosphokinase (CPK): level of the CPK enzyme in the blood (mcg/L)\n",
    "- diabetes: if the patient has diabetes (boolean)\n",
    "- ejection fraction: percentage of blood leaving the heart at each contraction (percentage)\n",
    "- platelets: platelets in the blood (kiloplatelets/mL)\n",
    "- sex: woman or man (binary)\n",
    "- serum creatinine: level of serum creatinine in the blood (mg/dL)\n",
    "- serum sodium: level of serum sodium in the blood (mEq/L)\n",
    "- smoking: if the patient smokes or not (boolean)\n",
    "- time: follow-up period (days)\n",
    "- death event: if the patient deceased during the follow-up period (boolean)\n",
    "\n",
    "1. Load the `./data/heart_failure_clinical_records_dataset.csv`. Are there any `NA`'s to handle? use `.drop()` to remove `time` from the dataframe.\n",
    "2. Make a correlation matrix. What variables are strongly associated with a death event?\n",
    "3. For the dummy variables `anaemia`, `diabetes`, `high_blood_pressure`, `sex`, and `smoking`, compute a summary table of `DEATH_EVENT` grouped by the variable. For which variables does a higher proportion of the population die when the variable takes the value 1 rather than 0?\n",
    "4. On the basis of your answers from 2 and 3, build a matrix $X$ of the variables you think are most predictive of a death, and a variable $y$ equal to `DEATH_EVENT`.\n",
    "5. Maxmin normalize all of the variables in `X`.\n",
    "6. Split the sample into ~80% for training and ~20% for evaluation. (Try to use the same train/test split for the whole question, so that you're comparing apples to apples in the questions below.).\n",
    "7. Determine the optimal number of neighbors for a $k$NN regression for the variables you selected.\n",
    "8. OK, do steps 5 through 7 again, but use all of the variables (except `time`). Which model has a lower Sum of Squared Error? Which would you prefer to use in practice, if you had to predict `DEATH_EVENT`s? If you play with the selection of variables, how much does the SSE change for your fitted model on the test data? Are more variables always better? Explain your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457e190-d273-455f-b94f-62916cb5af1c",
   "metadata": {},
   "source": [
    "**Q3.** Let's do some very basic computer vision. We're going to import the MNIST handwritten digits data and $k$NN to predict values (i.e. \"see/read\").\n",
    "\n",
    "1. To load the data, run the following code in a chunk:\n",
    "```\n",
    "from keras.datasets import mnist\n",
    "df = mnist.load_data('minst.db')\n",
    "train,test = df\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "```\n",
    "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
    "for i in range(5): \n",
    "    print(y_test[i],'\\n') # Print the label\n",
    "    print(X_test[i],'\\n') # Print the matrix of values\n",
    "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
    "    plt.show()\n",
    "```\n",
    "OK, those are the data: Labels attached to handwritten digits encoded as a matrix.\n",
    "\n",
    "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
    "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
    "4. Use the reshaped `X_test` and `y_test` data to create a $k$-nearest neighbor classifier of digit. What is the optimal number of neighbors $k$? If you can't determine this, play around with different values of $k$ for your classifier.\n",
    "5. For the optimal number of neighbors, how well does your predictor perform on the test set?\n",
    "6. So, this is how computers \"see.\" They convert an image into a matrix of values, that matrix becomes a vector in a dataset, and then we deploy ML tools on it as if it was any other kind of tabular data. To make sure you follow this, invent a way to represent a color photo in matrix form, and then describe how you could convert it into tabular data. (Hint: RGB color codes provide a method of encoding a numeric value that represents a color.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
