{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc23963-2cc5-4f1d-8278-fb1b2026afc5",
   "metadata": {
    "id": "cfc23963-2cc5-4f1d-8278-fb1b2026afc5"
   },
   "source": [
    "## Assignment: $k$ Means Clustering\n",
    "\n",
    "## **Do two questions.**\n",
    "\n",
    "`! git clone https://www.github.com/DS3001/kmc`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dae156-b49b-4f43-bc42-ad1589132891",
   "metadata": {
    "id": "85dae156-b49b-4f43-bc42-ad1589132891"
   },
   "source": [
    "**Q1.** This question is a case study for $k$ means clustering.\n",
    "\n",
    "1. Load the `airbnb_hw.csv` data. Clean `Price` along with `Beds`, `Number Of Reviews`, and `Review Scores Rating`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3c6621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30478, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "airbnb = pd.read_csv('airbnb_hw.csv')\n",
    "airbnb['N_Reviews'] = airbnb['Number Of Reviews']\n",
    "airbnb['Score'] = airbnb['Review Scores Rating']\n",
    "airbnb = airbnb.loc[:, ['Price', 'Beds', 'N_Reviews', 'Score']]\n",
    "print(airbnb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f0c34ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Price, Beds, N_Reviews, Score]\n",
      "Index: [] \n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Price, Beds, N_Reviews, Score]\n",
      "Index: [] \n",
      "\n",
      "Price\n",
      "150      1481\n",
      "100      1207\n",
      "200      1059\n",
      "125       889\n",
      "75        873\n",
      "         ... \n",
      "840         1\n",
      "306         1\n",
      "2,695       1\n",
      "2,520       1\n",
      "291         1\n",
      "Name: count, Length: 511, dtype: int64\n",
      "count    30478.000000\n",
      "mean       163.589737\n",
      "std        197.785454\n",
      "min         10.000000\n",
      "25%         80.000000\n",
      "50%        125.000000\n",
      "75%        195.000000\n",
      "max      10000.000000\n",
      "Name: Price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(airbnb.loc[airbnb['Price'] == ' '], '\\n')\n",
    "print(airbnb.loc[airbnb['Price'] == np.nan], '\\n')\n",
    "print(airbnb['Price'].value_counts())\n",
    "airbnb['Price'] = airbnb['Price'].str.replace(',','')\n",
    "airbnb['Price'] = pd.to_numeric(airbnb['Price'],errors='coerce')\n",
    "print(airbnb['Price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9bf181b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  3.  2.  4.  5. nan  6. 10.  7.  8. 12.  0. 16.  9. 11.]\n"
     ]
    }
   ],
   "source": [
    "print(airbnb['Beds'].unique())\n",
    "airbnb['Beds'] = airbnb['Beds'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "45ef2bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1  39   4   9  80  95  23  14 120  81  17  32  52   3 171  16  19\n",
      "   2  28  62   6   5  12  40  47  13  35  34  68  42   7  41  15  21   8\n",
      "  10  29 112  25 132  51 156  30  98  24  74  20 188 221  57  11 242  67\n",
      " 118  60 136 119  79 106  43  91 105  96 141 146  63  58  18 150  38  55\n",
      "  89  46  77  48  36  69  26  73  53 165  92  87 108 109  50 127  88  83\n",
      " 184 179  22  31  82  27 123 247 190 257 217  85 103 157 102  56 125 115\n",
      "  49  97  54  65  90  44  33 100  37 107 114 116  61 104  71  75 145  84\n",
      "  93 110 172 148 131 154  86  64  76 129  45 180 140  78 200 175 189 170\n",
      " 187  72 137  99 101  59  94 124 223 173 151 142 163 121 256 248 149 128\n",
      " 133  66 117 176 111  70 183 218 192 206 161 216 191 213 178 122 153 177\n",
      " 167 113 126 135 181 138 143 195 182 198 211 166 139 134 144 174 159 155\n",
      " 203 201 164 212 236 235 130]\n"
     ]
    }
   ],
   "source": [
    "print(airbnb['N_Reviews'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acf0a693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ nan  96. 100.  94.  90.  98.  93.  91.  97.  95.  99.  85.  86.  80.\n",
      "  88.  92.  89.  82.  87.  81.  76.  78.  83.  66.  84.  72.  79.  60.\n",
      "  40.  62.  74.  77.  50.  71.  75.  73.  69.  65.  68.  70.  67.  64.\n",
      "  20.  57.  58.  43.  63.  55.  47.  53.  49.  30.]\n",
      "(30478, 4)\n"
     ]
    }
   ],
   "source": [
    "print(airbnb['Score'].unique())\n",
    "print(airbnb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e1bcd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 96. 100.  94.  90.  98.  93.  91.  97.  95.  99.  85.  86.  80.  88.\n",
      "  92.  89.  82.  87.  81.  76.  78.  83.  66.  84.  72.  79.  60.  40.\n",
      "  62.  74.  77.  50.  71.  75.  73.  69.  65.  68.  70.  67.  64.  20.\n",
      "  57.  58.  43.  63.  55.  47.  53.  49.  30.]\n",
      "(22155, 4)\n"
     ]
    }
   ],
   "source": [
    "airbnb = airbnb.dropna(subset=[\"Score\"])\n",
    "print(airbnb['Score'].unique())\n",
    "print(airbnb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "77a6043b",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = airbnb.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529761e1",
   "metadata": {
    "id": "85dae156-b49b-4f43-bc42-ad1589132891"
   },
   "source": [
    "2. Maxmin normalize the data and remove any `nan`'s (`KMeans` from `sklearn` doesn't accept `nan` input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cef7db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmin(df):\n",
    "    df = (df-min(df))/(max(df)-min(df))\n",
    "    return df\n",
    "\n",
    "airbnb = airbnb.apply(maxmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea8890",
   "metadata": {
    "id": "85dae156-b49b-4f43-bc42-ad1589132891"
   },
   "source": [
    "3. Use `sklearn`'s `KMeans` module to cluster the data by `Beds`, `Number of Reviews`, and `Review Scores Rating` for `k=6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ddc7afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Beds  N_Reviews  Score\n",
      "4      0.1875   0.148438  0.950\n",
      "5      0.0625   0.011719  1.000\n",
      "6      0.0625   0.031250  1.000\n",
      "7      0.0625   0.308594  0.925\n",
      "8      0.1250   0.367188  0.875\n",
      "...       ...        ...    ...\n",
      "30332  0.0625   0.000000  1.000\n",
      "30347  0.0625   0.000000  0.750\n",
      "30378  0.0625   0.000000  1.000\n",
      "30404  0.0625   0.000000  1.000\n",
      "30409  0.0625   0.000000  0.750\n",
      "\n",
      "[22155 rows x 3 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, n_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Create a model for \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(data) \u001b[38;5;66;03m# Fit the emodel\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1526\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1526\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m kmeans_single(\n\u001b[1;32m   1527\u001b[0m     X,\n\u001b[1;32m   1528\u001b[0m     sample_weight,\n\u001b[1;32m   1529\u001b[0m     centers_init,\n\u001b[1;32m   1530\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1531\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1532\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tol,\n\u001b[1;32m   1533\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_threads,\n\u001b[1;32m   1534\u001b[0m )\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[1;32m   1541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1542\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m   1544\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:688\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[1;32m    684\u001b[0m strict_convergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# Threadpoolctl context to limit the number of threads in second level of\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# nested parallelism (i.e. BLAS) to avoid oversubscription.\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m threadpool_limits(limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblas\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iter):\n\u001b[1;32m    690\u001b[0m         lloyd_iter(\n\u001b[1;32m    691\u001b[0m             X,\n\u001b[1;32m    692\u001b[0m             sample_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    698\u001b[0m             n_threads,\n\u001b[1;32m    699\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py:72\u001b[0m, in \u001b[0;36mthreadpool_limits\u001b[0;34m(limits, user_api)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m threadpoolctl\u001b[38;5;241m.\u001b[39mthreadpool_limits(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:171\u001b[0m, in \u001b[0;36mthreadpool_limits.__init__\u001b[0;34m(self, limits, user_api)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(limits, user_api)\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_threadpool_limits()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:268\u001b[0m, in \u001b[0;36mthreadpool_limits._set_threadpool_limits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m modules \u001b[38;5;241m=\u001b[39m _ThreadpoolInfo(prefixes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefixes,\n\u001b[1;32m    269\u001b[0m                           user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_user_api)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# self._limits is a dict {key: num_threads} where key is either\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# a prefix or a user_api. If a module matches both, the limit\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# corresponding to the prefix is chosed.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39mprefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_limits:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_modules()\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:371\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_dyld()\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:428\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m filepath \u001b[38;5;241m=\u001b[39m filepath\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_module_from_path(filepath)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[1;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[0;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class(filepath, prefix, user_api, internal_api)\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_version()\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[0;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = airbnb.loc[:, ['Beds', 'N_Reviews', 'Score']]\n",
    "print(data)\n",
    "model = KMeans(n_clusters=6, max_iter=300, n_init = 10, random_state=0) # Create a model for \n",
    "model = model.fit(data) # Fit the emodel\n",
    "data['cluster'] = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c450a10",
   "metadata": {
    "id": "85dae156-b49b-4f43-bc42-ad1589132891"
   },
   "source": [
    "4. Use `seaborn`'s `.pairplot()` to make a grid of scatterplots that show how the clustering is carried out in multiple dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc60624",
   "metadata": {
    "id": "85dae156-b49b-4f43-bc42-ad1589132891"
   },
   "source": [
    "5. Use `.groupby` and `.describe` to compute the average price for each cluster. Which clusters have the highest rental prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de033a7",
   "metadata": {
    "id": "85dae156-b49b-4f43-bc42-ad1589132891"
   },
   "source": [
    "6. Use a scree plot to pick the number of clusters and repeat steps 4 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26523935-9e8f-4377-920c-6f65605c0e31",
   "metadata": {
    "id": "26523935-9e8f-4377-920c-6f65605c0e31"
   },
   "source": [
    "**Q2.** This is a question about $k$ means clustering. We want to investigate how adjusting the \"noisiness\" of the data impacts the quality of the algorithm and the difficulty of picking $k$.\n",
    "\n",
    "1. Run the code below, which creates four datasets: `df0_125`, `df0_25`, `df0_5`, `df1_0`, and `df2_0`. Each data set is created by increasing the amount of `noise` (standard deviation) around the cluster centers, from `0.125` to `0.25` to `0.5` to `1.0` to `2.0`.\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def createData(noise,N=50):\n",
    "    np.random.seed(100) # Set the seed for replicability\n",
    "    # Generate (x1,x2,g) triples:\n",
    "    X1 = np.array([np.random.normal(1,noise,N),np.random.normal(1,noise,N)])\n",
    "    X2 = np.array([np.random.normal(3,noise,N),np.random.normal(2,noise,N)])\n",
    "    X3 = np.array([np.random.normal(5,noise,N),np.random.normal(3,noise,N)])\n",
    "    # Concatenate into one data frame\n",
    "    gdf1 = pd.DataFrame({'x1':X1[0,:],'x2':X1[1,:],'group':'a'})\n",
    "    gdf2 = pd.DataFrame({'x1':X2[0,:],'x2':X2[1,:],'group':'b'})\n",
    "    gdf3 = pd.DataFrame({'x1':X3[0,:],'x2':X3[1,:],'group':'c'})\n",
    "    df = pd.concat([gdf1,gdf2,gdf3],axis=0)\n",
    "    return df\n",
    "\n",
    "df0_125 = createData(0.125)\n",
    "df0_25 = createData(0.25)\n",
    "df0_5 = createData(0.5)\n",
    "df1_0 = createData(1.0)\n",
    "df2_0 = createData(2.0)\n",
    "```\n",
    "\n",
    "2. Make scatterplots of the $(X1,X2)$ points by group for each of the datasets. As the `noise` goes up from 0.125 to 2.0, what happens to the visual distinctness of the clusters?\n",
    "3. Create a scree plot for each of the datasets. Describe how the level of `noise` affects the scree plot (particularly the presence of a clear \"elbow\") and your ability to definitively select a $k$.\n",
    "4. Explain the intuition of the elbow, using this numerical simulation as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870041b4-204b-4bc4-bf8a-3fe2f8734a58",
   "metadata": {
    "id": "870041b4-204b-4bc4-bf8a-3fe2f8734a58"
   },
   "source": [
    "**Q3.** We looked at computer vision with $k$NN in a previous question. Can $k$ means clustering correctly group digits, even if we don't know which symbols are which?\n",
    "\n",
    "1. To load the data, run the following code in a chunk:\n",
    "```\n",
    "from keras.datasets import mnist\n",
    "df = mnist.load_data('minst.db')\n",
    "train,test = df\n",
    "X_train, y_train = train\n",
    "X_test, y_test = test\n",
    "```\n",
    "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
    "```\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
    "for i in range(5):\n",
    "    print(y_test[i],'\\n') # Print the label\n",
    "    print(X_test[i],'\\n') # Print the matrix of values\n",
    "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
    "    plt.show()\n",
    "```\n",
    "OK, those are the data: Labels attached to handwritten digits encoded as a matrix.\n",
    "\n",
    "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
    "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
    "4. Use $k$ means clustering on the reshaped `X_test` data with `k=10`.  \n",
    "5. Cross tabulate the cluster assignments with the true labels for the test set values. How good is the correspondence? What proportion of digits are clustered correctly? Which digits are the hardest to distinguish from one another? Can $k$MC recover the latent digits 0 to 9, without even knowing what those digits were?\n",
    "6. If you use a scree plot to determine the number of clusters $k$, does it pick 10 (the true number of digits), or not? If it fails to pick $k=10$, which digits does it tend to combine into the same classification?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
